{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matlab.engine as engi\n",
    "import matlab as mat\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,roc_auc_score,recall_score,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src import SMOTE\n",
    "from src import CFS\n",
    "from src import metrices\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start matlab service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = engi.start_matlab()\n",
    "eng.addpath(r'src/matlab_CTKCCA/',nargout=0)\n",
    "eng.addpath(r'src/matlab_KS/',nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'result/result.csv'\n",
    "repeats = 20\n",
    "ratio = 0.1\n",
    "lrank = 70\n",
    "reg = 1E-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    commit_guru_path = 'data/commit_guru/' + project + '.csv'\n",
    "    understand_df = pd.read_csv(understand_path)\n",
    "    understand_df = understand_df.dropna(axis = 1,how='all')\n",
    "    cols_list = understand_df.columns.values.tolist()\n",
    "    for item in ['Kind', 'Name','commit_hash', 'Bugs']:\n",
    "        if item in cols_list:\n",
    "            cols_list.remove(item)\n",
    "            cols_list.insert(0,item)\n",
    "    understand_df = understand_df[cols_list]\n",
    "    commit_guru_df = pd.read_csv(commit_guru_path)\n",
    "    cols = understand_df.columns.tolist()\n",
    "    \n",
    "    commit_guru_df = commit_guru_df.drop(labels = ['parent_hashes','author_name','author_name',\n",
    "                                                   'author_email','fileschanged','author_date',\n",
    "                                                   'author_date_unix_timestamp', 'commit_message',\n",
    "                                                  'classification', 'fix', 'contains_bug','fixes',],axis=1)\n",
    "\n",
    "#     print(commit_guru_df.columns)\n",
    "    understand_df = understand_df.drop_duplicates(cols[4:len(cols)])\n",
    "    df = understand_df.merge(commit_guru_df,on='commit_hash')\n",
    "#     df = understand_df\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    df = df[cols]\n",
    "    for item in ['Kind', 'Name','commit_hash']:\n",
    "        if item in cols:\n",
    "            df = df.drop(labels = [item],axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    s_df,s_cols = apply_cfs(df)\n",
    "    y = s_df.Bugs\n",
    "    X = s_df.drop('Bugs',axis = 1)\n",
    "#     y = df.Bugs\n",
    "#     X = df.drop('Bugs',axis = 1)\n",
    "    cols = X.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X,columns = cols)\n",
    "    df = pd.concat([X,y],axis = 1)\n",
    "    return df\n",
    "\n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def apply_cfs(df):\n",
    "        y = df.Bugs.values\n",
    "        X = df.drop(labels = ['Bugs'],axis = 1)\n",
    "        X = X.values\n",
    "        selected_cols = CFS.cfs(X,y)\n",
    "        cols = df.columns[[selected_cols]].tolist()\n",
    "        cols.append('Bugs')\n",
    "        return df[cols],cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matlab integration\n",
    "## Matlab integration - CTKCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTKCCA(source_df,target_df):\n",
    "    mat_source_df = mat.double(source_df.values.T.tolist())\n",
    "    mat_target_df = mat.double(target_df.values.T.tolist())\n",
    "    X = eng.CTKCCA(mat_source_df,mat_target_df,nargout=4)\n",
    "    train_X,train_y = np.array(X[0]),np.array(X[1]).tolist()[0]\n",
    "    test_X,test_y = np.array(X[2]),np.array(X[3]).tolist()[0]\n",
    "    return train_X,train_y,test_X,test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teting using original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running CPDP with CTKCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7587782587782589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.96      0.90       462\n",
      "         1.0       0.84      0.56      0.67       189\n",
      "\n",
      "    accuracy                           0.84       651\n",
      "   macro avg       0.84      0.76      0.78       651\n",
      "weighted avg       0.84      0.84      0.83       651\n",
      "\n",
      "0.5098976000739683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.72      0.60       838\n",
      "         1.0       0.51      0.30      0.38       826\n",
      "\n",
      "    accuracy                           0.51      1664\n",
      "   macro avg       0.51      0.51      0.49      1664\n",
      "weighted avg       0.51      0.51      0.49      1664\n",
      "\n",
      "0.5025729553024102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.89      0.78     12345\n",
      "         1.0       0.31      0.11      0.17      5330\n",
      "\n",
      "    accuracy                           0.66     17675\n",
      "   macro avg       0.51      0.50      0.48     17675\n",
      "weighted avg       0.58      0.66      0.60     17675\n",
      "\n",
      "0.6324199066461571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.87      0.67      1109\n",
      "         1.0       0.79      0.40      0.53      1360\n",
      "\n",
      "    accuracy                           0.61      2469\n",
      "   macro avg       0.66      0.63      0.60      2469\n",
      "weighted avg       0.68      0.61      0.59      2469\n",
      "\n",
      "0.5700305855692397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.94      0.68       799\n",
      "         1.0       0.78      0.20      0.32       845\n",
      "\n",
      "    accuracy                           0.56      1644\n",
      "   macro avg       0.66      0.57      0.50      1644\n",
      "weighted avg       0.66      0.56      0.49      1644\n",
      "\n",
      "0.544695876750458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.93      0.86      2471\n",
      "         1.0       0.37      0.16      0.23       655\n",
      "\n",
      "    accuracy                           0.77      3126\n",
      "   macro avg       0.59      0.54      0.54      3126\n",
      "weighted avg       0.72      0.77      0.73      3126\n",
      "\n",
      "0.5251427909520021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.87      0.84      2697\n",
      "         1.0       0.25      0.18      0.21       653\n",
      "\n",
      "    accuracy                           0.73      3350\n",
      "   macro avg       0.53      0.53      0.53      3350\n",
      "weighted avg       0.70      0.73      0.72      3350\n",
      "\n",
      "0.5529390200038734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.98      0.92      6152\n",
      "         1.0       0.51      0.13      0.20      1081\n",
      "\n",
      "    accuracy                           0.85      7233\n",
      "   macro avg       0.69      0.55      0.56      7233\n",
      "weighted avg       0.81      0.85      0.81      7233\n",
      "\n",
      "0.4885918642015955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.86      0.71      3173\n",
      "         1.0       0.35      0.11      0.17      2015\n",
      "\n",
      "    accuracy                           0.57      5188\n",
      "   macro avg       0.48      0.49      0.44      5188\n",
      "weighted avg       0.50      0.57      0.50      5188\n",
      "\n",
      "0.5096899779764353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.71      0.64      1432\n",
      "         1.0       0.44      0.31      0.37      1073\n",
      "\n",
      "    accuracy                           0.54      2505\n",
      "   macro avg       0.51      0.51      0.50      2505\n",
      "weighted avg       0.52      0.54      0.52      2505\n",
      "\n",
      "0.5445375834370142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.93      0.77      2142\n",
      "         1.0       0.55      0.16      0.25      1209\n",
      "\n",
      "    accuracy                           0.65      3351\n",
      "   macro avg       0.61      0.54      0.51      3351\n",
      "weighted avg       0.62      0.65      0.58      3351\n",
      "\n",
      "0.47987859207235806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.76      0.66      1553\n",
      "         1.0       0.36      0.20      0.26      1032\n",
      "\n",
      "    accuracy                           0.54      2585\n",
      "   macro avg       0.47      0.48      0.46      2585\n",
      "weighted avg       0.50      0.54      0.50      2585\n",
      "\n",
      "0.5290559781446857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.93      0.69      3161\n",
      "         1.0       0.62      0.13      0.21      2788\n",
      "\n",
      "    accuracy                           0.55      5949\n",
      "   macro avg       0.58      0.53      0.45      5949\n",
      "weighted avg       0.58      0.55      0.46      5949\n",
      "\n",
      "0.8606486483807334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.73      0.84      2248\n",
      "         1.0       0.37      0.99      0.54       359\n",
      "\n",
      "    accuracy                           0.76      2607\n",
      "   macro avg       0.68      0.86      0.69      2607\n",
      "weighted avg       0.91      0.76      0.80      2607\n",
      "\n",
      "0.5530342012280882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.69      0.60       369\n",
      "         1.0       0.59      0.42      0.49       395\n",
      "\n",
      "    accuracy                           0.55       764\n",
      "   macro avg       0.56      0.55      0.54       764\n",
      "weighted avg       0.56      0.55      0.54       764\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fcc24d563579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msource_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md_project\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprojects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtarget_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_project\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Transforming metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrasformed_train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrasformed_train_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrasformed_test_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrasformed_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTKCCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8aac6246888a>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0ms_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_cfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBugs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bugs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8aac6246888a>\u001b[0m in \u001b[0;36mapply_cfs\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Bugs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mselected_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCFS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bugs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI4SE/TCKCCA/src/CFS.py\u001b[0m in \u001b[0;36mcfs\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;31m# calculate the merit of current selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerit_calculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmerit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mmerit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI4SE/TCKCCA/src/CFS.py\u001b[0m in \u001b[0;36mmerit_calculation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mrcf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msu_calculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI4SE/TCKCCA/src/CFS.py\u001b[0m in \u001b[0;36msu_calculation\u001b[0;34m(f1, f2)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropyd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;31m# su(f1,f2) = 2*t1/(t2+t3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0msu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "precision_list = {}\n",
    "recall_list = {}\n",
    "pf_list = {}\n",
    "f1_list = {}\n",
    "g_list = {}\n",
    "auc_list = {}\n",
    "proj_df = pd.read_csv('projects.csv')\n",
    "projects = proj_df.repo_name.tolist()\n",
    "for s_project in projects:\n",
    "    try:\n",
    "        if s_project not in precision_list.keys():\n",
    "            precision_list[s_project] = {}\n",
    "            recall_list[s_project] = {}\n",
    "            pf_list[s_project] = {}\n",
    "            f1_list[s_project] = {}\n",
    "            g_list[s_project] = {}\n",
    "            auc_list[s_project] = {} \n",
    "        source_df = load_data(s_project)\n",
    "        source_df = apply_smote(source_df)\n",
    "        for d_project in projects:\n",
    "            try:\n",
    "                target_df = load_data(d_project)\n",
    "                # Transforming metrics\n",
    "                trasformed_train_X,trasformed_train_y,trasformed_test_X,trasformed_test_y = CTKCCA(source_df,target_df)\n",
    "        #         train_df = pd.DataFrame(trasformed_train_X)\n",
    "        #         train_df['Bugs'] = trasformed_train_y\n",
    "        #         train_df = apply_smote(train_df)\n",
    "        #         trasformed_train_y = train_df.Bugs\n",
    "        #         trasformed_train_X = train_df.drop('Bugs',axis = 1)\n",
    "                #Training Model & Predicting\n",
    "                t_clf = LogisticRegression()\n",
    "                t_clf.fit(trasformed_train_X,trasformed_train_y)\n",
    "                t_predicted = t_clf.predict(trasformed_test_X)\n",
    "                # Calculating metrics\n",
    "                abcd = metrices.measures(trasformed_test_y,t_predicted)\n",
    "                pf = abcd.get_pf()\n",
    "                recall = abcd.calculate_recall()\n",
    "                precision = abcd.calculate_precision()\n",
    "                f1 = abcd.calculate_f1_score()\n",
    "                g_score = abcd.get_g_score()\n",
    "                auc = roc_auc_score(trasformed_test_y, t_predicted)\n",
    "                # Storing Performance scores\n",
    "                precision_list[s_project][d_project] = precision\n",
    "                recall_list[s_project][d_project] = recall\n",
    "                pf_list[s_project][d_project] = pf\n",
    "                f1_list[s_project][d_project] = f1\n",
    "                g_list[s_project][d_project] = g_score\n",
    "                auc_list[s_project][d_project] = auc\n",
    "                print(classification_report(trasformed_test_y, t_predicted))\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        continue\n",
    "final_result = {}\n",
    "final_result['precision'] = precision_list\n",
    "final_result['recall'] = recall_list\n",
    "final_result['pf'] = pf_list\n",
    "final_result['f1'] = f1_list\n",
    "final_result['g'] = g_list\n",
    "final_result['auc'] = auc_list\n",
    "with open('results/Performance/KS_100.pkl', 'wb') as handle:\n",
    "    pickle.dump(final_result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
